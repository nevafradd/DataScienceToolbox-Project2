{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9013a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required libraries for this evaluation script\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import kagglehub\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "import math\n",
    "from typing import List, Tuple\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import EfficientNet_B0_Weights\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8929a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version of the dataset and follow procedure in initial file\n",
    "path = kagglehub.dataset_download(\"meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\")\n",
    "\n",
    "test_df_path =  os.path.join(path, \"Test.csv\")\n",
    "test_img_path =  os.path.join(path, \"Test\")\n",
    "test_df = pd.read_csv(test_df_path)\n",
    "\n",
    "class_names = {\n",
    "    0:\"Speed Limit (20Km/hr)\", 1:\"Speed Limit (30Km/hr)\", \n",
    "    2:\"Speed Limit (50Km/hr)\", 3: \"Speed Limit (60Km/hr)\", \n",
    "    4: \"Speed Limit (70Km/hr)\", 5: \"Speed Limit (80Km/hr)\",\n",
    "    6: \"End of Speed Limit (80Km/hr)\", 7: \"Speed Limit (100Km/hr)\", \n",
    "    8: \"Speed Limit (120Km/hr)\", 9: \"No Passing\", \n",
    "    10: \"No Passing for trucks over 3.5 tons\", 11: \"Right of way\", \n",
    "    12: \"Priotity Road\", 13: \"Yeild right of way\",\n",
    "    14: \"Stop\", 15: \"Prohibited for all vehicles\",\n",
    "    16: \"Trucks and tractors over 3.5 tons prohibited\", 17: \"Entery prohibited\",\n",
    "    18: \"Danger\", 19: \"Single curve left\",\n",
    "    20: \"Single curve right\", 21: \"Double curve\",\n",
    "    22: \"Rough road\", 23: \"Slippery road\",\n",
    "    24: \"Road narrows\", 25: \"Construction side ahead\",\n",
    "    26: \"Signal lights ahead\", 27: \"Pedestrian crosswalk ahead\",\n",
    "    28: \"Children\", 29: \"Bicycle crossing\",\n",
    "    30: \"Unexpected ice danger\", 31: \"Wild animal crossing\",\n",
    "    32: \"End of restrection\", 33: \"Mandatory direction of travel right\",\n",
    "    34: \"Mandatory direction of travel left\", 35: \"Mandatory direction of travel ahead\",\n",
    "    36: \"Straight or right\", 37: \"Straight or left\",\n",
    "    38: \"Keep right\", 39: \"Keep left\",\n",
    "    40: \"Traffic circle\", 41: \"End of no passing zone cars\",\n",
    "    42: \"End of no passing zone vehicle over 3.5 tons\"\n",
    "}\n",
    "\n",
    "test_df[\"ClassName\"] = test_df['ClassId'].map(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3902065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "#test transform (no augmentation)\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb28d999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loader: 198 batches\n"
     ]
    }
   ],
   "source": [
    "class GTSRBDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root_dir = Path(root_dir)      # <-- convert to Path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.root_dir / row[\"Path\"]   # Path object\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(row[\"ClassId\"])\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "test_dataset = GTSRBDataset(test_df, root_dir=path, transform=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Test loader: {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a1a1177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): EfficientNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (8): Conv2dNormActivation(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (1): Linear(in_features=1280, out_features=256, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.4, inplace=False)\n",
       "  (4): Linear(in_features=256, out_features=43, bias=True)\n",
       "  (5): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved weights\n",
    "NUM_CLASSES = 43\n",
    "\n",
    "# Load EfficientNet base model\n",
    "weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "base_model = efficientnet_b0(weights=weights)\n",
    "\n",
    "# Remove classifier â†’ keep global avg pooling only\n",
    "base_model.classifier = nn.Identity()\n",
    "\n",
    "# Freeze base model\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Build the same custom head Neva used\n",
    "model = nn.Sequential(\n",
    "    base_model,                # (0)\n",
    "    nn.Linear(1280, 256),      # (2)\n",
    "    nn.ReLU(),                 # (3)\n",
    "    nn.Dropout(0.4),           # (4)\n",
    "    nn.Linear(256, NUM_CLASSES),  # (5)\n",
    "    nn.Softmax(dim=1)          # (6)\n",
    ")\n",
    "\n",
    "# Load the saved weights\n",
    "state_dict = torch.load(\"Neva/efficientnet_best.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92d607a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=43, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet18 = models.resnet18(weights=None)\n",
    "model_resnet18.fc = torch.nn.Linear(512, 43)   # example for 43 traffic signs\n",
    "state_dict_resnet18 = torch.load(\"Gracie/resnet18_traffic_signs.pth\", map_location=\"cpu\")\n",
    "model_resnet18.load_state_dict(state_dict_resnet18)\n",
    "model_resnet18.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f34c688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Speed Limit (20Km/hr)', 1: 'Speed Limit (30Km/hr)', 2: 'Speed Limit (50Km/hr)', 3: 'Speed Limit (60Km/hr)', 4: 'Speed Limit (70Km/hr)', 5: 'Speed Limit (80Km/hr)', 6: 'End of Speed Limit (80Km/hr)', 7: 'Speed Limit (100Km/hr)', 8: 'Speed Limit (120Km/hr)', 9: 'No Passing', 10: 'No Passing for trucks over 3.5 tons', 11: 'Right of way', 12: 'Priotity Road', 13: 'Yeild right of way', 14: 'Stop', 15: 'Prohibited for all vehicles', 16: 'Trucks and tractors over 3.5 tons prohibited', 17: 'Entery prohibited', 18: 'Danger', 19: 'Single curve left', 20: 'Single curve right', 21: 'Double curve', 22: 'Rough road', 23: 'Slippery road', 24: 'Road narrows', 25: 'Construction side ahead', 26: 'Signal lights ahead', 27: 'Pedestrian crosswalk ahead', 28: 'Children', 29: 'Bicycle crossing', 30: 'Unexpected ice danger', 31: 'Wild animal crossing', 32: 'End of restrection', 33: 'Mandatory direction of travel right', 34: 'Mandatory direction of travel left', 35: 'Mandatory direction of travel ahead', 36: 'Straight or right', 37: 'Straight or left', 38: 'Keep right', 39: 'Keep left', 40: 'Traffic circle', 41: 'End of no passing zone cars', 42: 'End of no passing zone vehicle over 3.5 tons'}\n"
     ]
    }
   ],
   "source": [
    "class_names = test_loader.dataset.class_names if hasattr(test_loader.dataset, 'class_names') else class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)            \n",
    "model_resnet18.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize metrics\n",
    "correct_eff = correct_res = top5_correct_eff = top5_correct_res = total = 0\n",
    "running_loss_eff = running_loss_res = 0.0\n",
    "all_labels, all_pred_eff, all_pred_res = [], [], []\n",
    "\n",
    "model.eval()\n",
    "model_resnet18.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        \n",
    "        # EfficientNet\n",
    "        outputs_eff = model(images)\n",
    "        _, pred_eff = torch.max(outputs_eff, 1)\n",
    "        _, top5_eff = torch.topk(outputs_eff, 5, dim=1)\n",
    "        correct_eff += (pred_eff == labels).sum().item()\n",
    "        top5_correct_eff += (top5_eff == labels.unsqueeze(1)).any(dim=1).sum().item()\n",
    "        running_loss_eff += criterion(outputs_eff, labels).item() * batch_size\n",
    "        \n",
    "        # ResNet18\n",
    "        outputs_res = model_resnet18(images)\n",
    "        _, pred_res = torch.max(outputs_res, 1)\n",
    "        _, top5_res = torch.topk(outputs_res, 5, dim=1)\n",
    "        correct_res += (pred_res == labels).sum().item()\n",
    "        top5_correct_res += (top5_res == labels.unsqueeze(1)).any(dim=1).sum().item()\n",
    "        running_loss_res += criterion(outputs_res, labels).item() * batch_size\n",
    "        \n",
    "        # Store predictions\n",
    "        total += batch_size\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_pred_eff.append(pred_eff.cpu().numpy())\n",
    "        all_pred_res.append(pred_res.cpu().numpy())\n",
    "\n",
    "# Calculate final metrics\n",
    "accuracy_eff = 100 * correct_eff / total\n",
    "top5_accuracy_eff = 100 * top5_correct_eff / total\n",
    "avg_loss_eff = running_loss_eff / total\n",
    "\n",
    "accuracy_res = 100 * correct_res / total\n",
    "top5_accuracy_res = 100 * top5_correct_res / total\n",
    "avg_loss_res = running_loss_res / total\n",
    "\n",
    "print(f\"Test Accuracy for EfficientNet: {accuracy_eff:.2f}%  | Top-5: {top5_accuracy_eff:.2f}% | Loss: {avg_loss_eff:.4f}\")\n",
    "print(f\"Test Accuracy for ResNet18:     {accuracy_res:.2f}%  | Top-5: {top5_accuracy_res:.2f}% | Loss: {avg_loss_res:.4f}\")\n",
    "\n",
    "# Concatenate for further analysis\n",
    "y_true = np.concatenate(all_labels)\n",
    "y_pred_eff = np.concatenate(all_pred_eff)\n",
    "y_pred_res = np.concatenate(all_pred_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcda71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_model(model, test_loader, device):\n",
    "    model.to(device).eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images.to(device))\n",
    "            all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    report_dict = classification_report(all_labels, all_preds, zero_division=0, output_dict=True)\n",
    "    df_metrics = pd.DataFrame(report_dict).transpose()\n",
    "    \n",
    "    return df_metrics, all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1def3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effnet, true_effnet, pred_effnet = classification_report_model(model, test_loader, device)\n",
    "cm = confusion_matrix(true_effnet, pred_effnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa581fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_effnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09774465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resnet, true_resnet, pred_resnet = classification_report_model(model_resnet18, test_loader, device)\n",
    "cm_resnet = confusion_matrix(true_resnet, pred_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc92308",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm, annot=False, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix for Efficient Net Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm_resnet, annot=False, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix for ResNet18 Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c45275",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_eff = df_effnet.loc[\"weighted avg\", \"precision\"]\n",
    "recall_eff = df_effnet.loc[\"weighted avg\", \"recall\"]\n",
    "f1_eff = df_effnet.loc[\"weighted avg\", \"f1-score\"]\n",
    "\n",
    "precision_res = df_resnet.loc[\"weighted avg\", \"precision\"]\n",
    "recall_res = df_resnet.loc[\"weighted avg\", \"recall\"]\n",
    "f1_res = df_resnet.loc[\"weighted avg\", \"f1-score\"]\n",
    "\n",
    "print(f\"EfficientNet - Macro Precision: {precision_eff:.4f}, Macro Recall: {recall_eff:.4f}, Macro F1-Score: {f1_eff:.4f}\\n\")\n",
    "print(f\"ResNet18   - Macro Precision: {precision_res:.4f}, Macro Recall: {recall_res:.4f}, Macro F1-Score: {f1_res:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f390fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_classes_eff= df_effnet.iloc[:-3].sort_values(\"recall\").head(5)\n",
    "worst_classes_res= df_resnet.iloc[:-3].sort_values(\"recall\").head(5)\n",
    "\n",
    "print(worst_classes_eff, \"\\n\")\n",
    "print(worst_classes_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a5e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_misclassified(model, loader, device, class_names, max_images=16):\n",
    "    model.eval()\n",
    "    misclassified = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            preds = model(images).argmax(1)\n",
    "            \n",
    "            for img, true, pred in zip(images[preds != labels], \n",
    "                                       labels[preds != labels], \n",
    "                                       preds[preds != labels]):\n",
    "                misclassified.append((img.cpu(), true.item(), pred.item()))\n",
    "                if len(misclassified) >= max_images:\n",
    "                    break\n",
    "            if len(misclassified) >= max_images:\n",
    "                break\n",
    "    \n",
    "    # Setup plot\n",
    "    n = len(misclassified)\n",
    "    cols = 4\n",
    "    rows = (n + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(3*cols, 3*rows))\n",
    "    axes = axes.flatten() if n > 1 else [axes]\n",
    "    \n",
    "    # Denormalization constants\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    # Plot each misclassified image\n",
    "    for i, (img, true, pred) in enumerate(misclassified):\n",
    "        img = ((img * std + mean).permute(1, 2, 0).clamp(0, 1))\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis(\"off\")\n",
    "        axes[i].set_title(f\"T: {class_names[true]}\\nP: {class_names[pred]}\", \n",
    "                          fontsize=10)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n, len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test it\n",
    "show_misclassified(model_resnet18, test_loader, device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc486540",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_misclassified(model, test_loader, device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_correct = (y_pred_eff == y_true) & (y_pred_res == y_true)\n",
    "eff_only     = (y_pred_eff == y_true) & (y_pred_res != y_true)\n",
    "res_only     = (y_pred_eff != y_true) & (y_pred_res == y_true)\n",
    "both_wrong   = (y_pred_eff != y_true) & (y_pred_res != y_true)\n",
    "\n",
    "print(f\"Samples both correct:    {both_correct.sum()}\")\n",
    "print(f\"EfficientNet only right: {eff_only.sum()}\")\n",
    "print(f\"ResNet18 only right:     {res_only.sum()}\")\n",
    "print(f\"Both wrong:              {both_wrong.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79dd4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def measure_latency(model, dataloader, n_batches=10):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    times = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, _) in enumerate(dataloader):\n",
    "            if i >= n_batches:\n",
    "                break\n",
    "            images = images.to(device)\n",
    "\n",
    "            torch.cuda.synchronize() if device.type == \"cuda\" else None\n",
    "            t0 = time.perf_counter()\n",
    "            _ = model(images)\n",
    "            torch.cuda.synchronize() if device.type == \"cuda\" else None\n",
    "            t1 = time.perf_counter()\n",
    "\n",
    "            times.append((t1 - t0) / images.size(0))  # seconds / image\n",
    "\n",
    "    return np.mean(times), np.std(times)\n",
    "\n",
    "mean_eff, std_eff = measure_latency(model, test_loader)\n",
    "mean_res, std_res = measure_latency(model_resnet18, test_loader)\n",
    "\n",
    "print(f\"EfficientNet: {mean_eff*1000:.2f} Â± {std_eff*1000:.2f} ms / image\")\n",
    "print(f\"ResNet18:     {mean_res*1000:.2f} Â± {std_res*1000:.2f} ms / image\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
