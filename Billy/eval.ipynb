{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac678f4",
   "metadata": {},
   "source": [
    "## Evaluating EfficientNet and ResNet18 on German Traffic Sign Dataset\n",
    "### Billy Ryan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c979f36a",
   "metadata": {},
   "source": [
    "### Outline:\n",
    "- Run final models (EfficientNet and ResNet18) on test set\n",
    "- Compute basic statistics / visualisation and make inferences\n",
    "- Observe statistics over all classes to identify trends\n",
    "- Check common misclassified images in individual models and in both models\n",
    "- Compute image process time of models and make inferences\n",
    "- Draw conclusions given findings\n",
    "- Link to further study and reference other sections of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e8d834",
   "metadata": {},
   "source": [
    "We begin our evaluation with importing functions from previous sections (see Neva and Gracie's work, and my previous files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9013a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required libraries for this evaluation script\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import kagglehub\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "import math\n",
    "from typing import List, Tuple\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import EfficientNet_B0_Weights\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8929a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version of the dataset and follow procedure in initial file\n",
    "path = kagglehub.dataset_download(\"meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\")\n",
    "\n",
    "test_df_path =  os.path.join(path, \"Test.csv\")\n",
    "test_img_path =  os.path.join(path, \"Test\")\n",
    "test_df = pd.read_csv(test_df_path)\n",
    "\n",
    "class_names = {\n",
    "    0:\"Speed Limit (20Km/hr)\", 1:\"Speed Limit (30Km/hr)\", \n",
    "    2:\"Speed Limit (50Km/hr)\", 3: \"Speed Limit (60Km/hr)\", \n",
    "    4: \"Speed Limit (70Km/hr)\", 5: \"Speed Limit (80Km/hr)\",\n",
    "    6: \"End of Speed Limit (80Km/hr)\", 7: \"Speed Limit (100Km/hr)\", \n",
    "    8: \"Speed Limit (120Km/hr)\", 9: \"No Passing\", \n",
    "    10: \"No Passing for trucks over 3.5 tons\", 11: \"Right of way\", \n",
    "    12: \"Priotity Road\", 13: \"Yeild right of way\",\n",
    "    14: \"Stop\", 15: \"Prohibited for all vehicles\",\n",
    "    16: \"Trucks and tractors over 3.5 tons prohibited\", 17: \"Entery prohibited\",\n",
    "    18: \"Danger\", 19: \"Single curve left\",\n",
    "    20: \"Single curve right\", 21: \"Double curve\",\n",
    "    22: \"Rough road\", 23: \"Slippery road\",\n",
    "    24: \"Road narrows\", 25: \"Construction side ahead\",\n",
    "    26: \"Signal lights ahead\", 27: \"Pedestrian crosswalk ahead\",\n",
    "    28: \"Children\", 29: \"Bicycle crossing\",\n",
    "    30: \"Unexpected ice danger\", 31: \"Wild animal crossing\",\n",
    "    32: \"End of restrection\", 33: \"Mandatory direction of travel right\",\n",
    "    34: \"Mandatory direction of travel left\", 35: \"Mandatory direction of travel ahead\",\n",
    "    36: \"Straight or right\", 37: \"Straight or left\",\n",
    "    38: \"Keep right\", 39: \"Keep left\",\n",
    "    40: \"Traffic circle\", 41: \"End of no passing zone cars\",\n",
    "    42: \"End of no passing zone vehicle over 3.5 tons\"\n",
    "}\n",
    "\n",
    "test_df[\"ClassName\"] = test_df['ClassId'].map(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff308a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we are in the project directory to call upon mdodels and data correctly\n",
    "os.chdir(\"C:/Users/billy/DataScienceToolbox-Project2\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3902065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define normalization constants for imagenet\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# test transform (no augmentation)\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset class\n",
    "class GTSRBDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root_dir = Path(root_dir)      # <-- convert to Path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.root_dir / row[\"Path\"]   # Path object\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(row[\"ClassId\"])\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# create test dataset and dataloader\n",
    "test_dataset = GTSRBDataset(test_df, root_dir=path, transform=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1a1177",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 43\n",
    "\n",
    "# Load EfficientNet base model\n",
    "weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "base_model = efficientnet_b0(weights=weights)\n",
    "\n",
    "# remove classifier\n",
    "base_model.classifier = nn.Identity()\n",
    "\n",
    "# freeze base model\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# build the full model\n",
    "model_eff = nn.Sequential(\n",
    "    base_model,                # (0)\n",
    "    nn.Linear(1280, 256),      # (2)\n",
    "    nn.ReLU(),                 # (3)\n",
    "    nn.Dropout(0.4),           # (4)\n",
    "    nn.Linear(256, NUM_CLASSES),  # (5)\n",
    "    nn.Softmax(dim=1)          # (6)\n",
    ")\n",
    "\n",
    "# load the saved weights\n",
    "state_dict = torch.load(\"Neva/efficientnet_best.pth\", map_location=\"cpu\")\n",
    "model_eff.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d607a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet18 = models.resnet18(weights=None)\n",
    "model_resnet18.fc = torch.nn.Linear(512, 43)   # example for 43 traffic signs\n",
    "state_dict_resnet18 = torch.load(\"Gracie/resnet18_traffic_signs.pth\", map_location=\"cpu\")\n",
    "model_resnet18.load_state_dict(state_dict_resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# require these for later cells\n",
    "class_names = test_loader.dataset.class_names if hasattr(test_loader.dataset, 'class_names') else class_names\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3890750c",
   "metadata": {},
   "source": [
    "Below, we finally train our models using the weights that Neva and Gracie found for their respective models. This cell may take some time to run but will output the accuracy and loss of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eff.to(device)            \n",
    "model_resnet18.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize metrics\n",
    "correct_eff = correct_res = top5_correct_eff = top5_correct_res = total = 0\n",
    "running_loss_eff = running_loss_res = 0.0\n",
    "all_labels, all_pred_eff, all_pred_res = [], [], []\n",
    "\n",
    "model_eff.eval()\n",
    "model_resnet18.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        \n",
    "        # EfficientNet\n",
    "        outputs_eff = model(images)\n",
    "        _, pred_eff = torch.max(outputs_eff, 1)\n",
    "        _, top5_eff = torch.topk(outputs_eff, 5, dim=1)\n",
    "        correct_eff += (pred_eff == labels).sum().item()\n",
    "        top5_correct_eff += (top5_eff == labels.unsqueeze(1)).any(dim=1).sum().item()\n",
    "        running_loss_eff += criterion(outputs_eff, labels).item() * batch_size\n",
    "        \n",
    "        # ResNet18\n",
    "        outputs_res = model_resnet18(images)\n",
    "        _, pred_res = torch.max(outputs_res, 1)\n",
    "        _, top5_res = torch.topk(outputs_res, 5, dim=1)\n",
    "        correct_res += (pred_res == labels).sum().item()\n",
    "        top5_correct_res += (top5_res == labels.unsqueeze(1)).any(dim=1).sum().item()\n",
    "        running_loss_res += criterion(outputs_res, labels).item() * batch_size\n",
    "        \n",
    "        # store predictions\n",
    "        total += batch_size\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_pred_eff.append(pred_eff.cpu().numpy())\n",
    "        all_pred_res.append(pred_res.cpu().numpy())\n",
    "\n",
    "# calculate desired metrics (test accuracy, top-5 accuracy, avg loss)\n",
    "accuracy_eff = 100 * correct_eff / total\n",
    "top5_accuracy_eff = 100 * top5_correct_eff / total\n",
    "avg_loss_eff = running_loss_eff / total\n",
    "\n",
    "accuracy_res = 100 * correct_res / total\n",
    "top5_accuracy_res = 100 * top5_correct_res / total\n",
    "avg_loss_res = running_loss_res / total\n",
    "\n",
    "print(f\"Test Accuracy for EfficientNet: {accuracy_eff:.2f}%  | Top-5: {top5_accuracy_eff:.2f}% | Loss: {avg_loss_eff:.4f}\")\n",
    "print(f\"Test Accuracy for ResNet18:     {accuracy_res:.2f}%  | Top-5: {top5_accuracy_res:.2f}% | Loss: {avg_loss_res:.4f}\")\n",
    "\n",
    "# need for further analysis\n",
    "y_true = np.concatenate(all_labels)\n",
    "y_pred_eff = np.concatenate(all_pred_eff)\n",
    "y_pred_res = np.concatenate(all_pred_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68d9b12",
   "metadata": {},
   "source": [
    "Talk about accuracy, top-5 and loss here:\n",
    "[1] https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html, [2] https://www.datacamp.com/tutorial/loss-function-in-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6ad00f",
   "metadata": {},
   "source": [
    "Now we wish to look at measures such as precision, accuracy and f1-score. TALK ABOUT THEM HERE...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59995fb1",
   "metadata": {},
   "source": [
    "Below is a function that will output a classification report, which contains our desired metrics, allowing us to compute useful plots and make inferences about the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcda71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_model(model, test_loader, device):\n",
    "    model.to(device).eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images.to(device))\n",
    "            all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    report_dict = classification_report(all_labels, all_preds, zero_division=0, output_dict=True)\n",
    "    df_metrics = pd.DataFrame(report_dict).transpose()\n",
    "    \n",
    "    return df_metrics, all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1def3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effnet, true_effnet, pred_effnet = classification_report_model(model_eff, test_loader, device)\n",
    "cm = confusion_matrix(true_effnet, pred_effnet)\n",
    "print(df_effnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09774465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resnet, true_resnet, pred_resnet = classification_report_model(model_resnet18, test_loader, device)\n",
    "cm_resnet = confusion_matrix(true_resnet, pred_resnet)\n",
    "print(df_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm, annot=False, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix for Efficient Net Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm_resnet, annot=False, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix for ResNet18 Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c45275",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_eff_weighted = df_effnet.loc[\"weighted avg\", \"precision\"]\n",
    "recall_eff_weighted = df_effnet.loc[\"weighted avg\", \"recall\"]\n",
    "f1_eff_weighted = df_effnet.loc[\"weighted avg\", \"f1-score\"]\n",
    "\n",
    "precision_res_weighted = df_resnet.loc[\"weighted avg\", \"precision\"]\n",
    "recall_res_weighted = df_resnet.loc[\"weighted avg\", \"recall\"]\n",
    "f1_res_weighted = df_resnet.loc[\"weighted avg\", \"f1-score\"]\n",
    "\n",
    "print(f\"EfficientNet - Macro Precision: {precision_eff_weighted:.4f}, Macro Recall: {recall_eff_weighted:.4f}, Macro F1-Score: {f1_eff_weighted:.4f}\\n\")\n",
    "print(f\"ResNet18   - Macro Precision: {precision_res_weighted:.4f}, Macro Recall: {recall_res_weighted:.4f}, Macro F1-Score: {f1_res_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f390fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_worst_classes(df, model_name, n=5):\n",
    "    worst = (df.iloc[:-3].sort_values(\"recall\").head(n)[[\"precision\", \"recall\", \"f1-score\", \"support\"]].round(3))\n",
    "\n",
    "    print(f\"\\n{model_name} – {n} worst classes (by recall)\\n\")\n",
    "    print(worst.to_string())\n",
    "\n",
    "show_worst_classes(df_effnet, \"EfficientNet\")\n",
    "show_worst_classes(df_resnet, \"ResNet18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc2dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eff = df_effnet.iloc[:-3] \n",
    "res = df_resnet.iloc[:-3]\n",
    "classes = eff.index.astype(int)\n",
    "\n",
    "recall_eff = eff[\"recall\"].values   # vector length 43\n",
    "recall_res = res[\"recall\"].values\n",
    "\n",
    "diff_recall = recall_eff - recall_res\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "#recall plot\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(classes, recall_eff, marker='o', label=\"EfficientNet Recall\", linewidth=2)\n",
    "plt.plot(classes, recall_res, marker='s', label=\"ResNet18 Recall\", linewidth=2)\n",
    "plt.title(\"Recall per Class for EfficientNet vs ResNet18\", fontsize=16)\n",
    "plt.xlabel(\"Class ID\", fontsize=14)\n",
    "plt.ylabel(\"Recall\", fontsize=14)\n",
    "plt.xticks(classes, rotation=90)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "\n",
    "# diff plot\n",
    "plt.subplot(2,1,2)\n",
    "plt.bar(classes, diff_recall, color='#5F98E2')\n",
    "plt.axhline(0, color=\"black\")\n",
    "plt.ylim(min(diff_recall) - 0.05, max(diff_recall) + 0.05)\n",
    "plt.title(\"Recall Difference per Class (EfficientNet - ResNet18)\", fontsize=16)\n",
    "plt.xlabel(\"Class ID\", fontsize=14)\n",
    "plt.ylabel(\"Recall Difference\", fontsize=14)\n",
    "plt.xticks(classes, rotation=90)\n",
    "plt.grid(True, alpha=0.4)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ba4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_eff = eff[\"precision\"].values \n",
    "precision_res = res[\"precision\"].values   \n",
    " \n",
    "diff_precision = precision_eff - precision_res\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "#precision plot\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(classes, precision_eff, marker='o', label=\"EfficientNet Precision\", linewidth=2)\n",
    "plt.plot(classes, precision_res, marker='s', label=\"ResNet18 Precision\", linewidth=2)\n",
    "plt.title(\"Precision per Class for EfficientNet vs ResNet18\", fontsize=16)\n",
    "plt.xlabel(\"Class ID\", fontsize=14)\n",
    "plt.ylabel(\"Precision\", fontsize=14)\n",
    "plt.xticks(classes, rotation=90)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "\n",
    "# diff plot\n",
    "plt.subplot(2,1,2)\n",
    "plt.bar(classes, diff_precision, color='#5F98E2')\n",
    "plt.axhline(0, color=\"black\")\n",
    "plt.ylim(min(diff_precision) - 0.05, max(diff_precision) + 0.05)\n",
    "plt.title(\"Precision Difference per Class (EfficientNet - ResNet18)\", fontsize=16)\n",
    "plt.xlabel(\"Class ID\", fontsize=14)\n",
    "plt.ylabel(\"Precision Difference\", fontsize=14)\n",
    "plt.xticks(classes, rotation=90)\n",
    "plt.grid(True, alpha=0.4)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89057c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_eff = eff[\"f1-score\"].values \n",
    "f1_res = res[\"f1-score\"].values   \n",
    " \n",
    "diff_f1 = f1_eff - f1_res\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "# f1 plot\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(classes, f1_eff, marker='o', label=\"EfficientNet F1 Score\", linewidth=2)\n",
    "plt.plot(classes, f1_res, marker='s', label=\"ResNet18 F1 Score\", linewidth=2)\n",
    "plt.title(\"F1 Score per Class for EfficientNet vs ResNet18\", fontsize=16)\n",
    "plt.xlabel(\"Class ID\", fontsize=14)\n",
    "plt.ylabel(\"F1 Score\", fontsize=14)\n",
    "plt.xticks(classes, rotation=90)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "\n",
    "# diff plot\n",
    "plt.subplot(2,1,2)\n",
    "plt.bar(classes, diff_f1, color='#5F98E2')\n",
    "plt.axhline(0, color=\"black\")\n",
    "plt.ylim(min(diff_f1) - 0.05, max(diff_f1) + 0.05)\n",
    "plt.title(\"F1 Score Difference per Class (EfficientNet - ResNet18)\", fontsize=16)\n",
    "plt.xlabel(\"Class ID\", fontsize=14)\n",
    "plt.ylabel(\"F1 Score Difference\", fontsize=14)\n",
    "plt.xticks(classes, rotation=90)\n",
    "plt.grid(True, alpha=0.4)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a5e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_misclassified(model, loader, device, class_names, max_images=16):\n",
    "    model.eval()\n",
    "    misclassified = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            preds = model(images).argmax(1)\n",
    "            \n",
    "            # find misclassified samples\n",
    "            mask = preds != labels\n",
    "            for img, true_label, pred_label in zip(images[mask], labels[mask], preds[mask]):\n",
    "                misclassified.append((img.cpu(), true_label.item(), pred_label.item()))\n",
    "                if len(misclassified) >= max_images:\n",
    "                    break\n",
    "            \n",
    "            if len(misclassified) >= max_images:\n",
    "                break\n",
    "    \n",
    "    if not misclassified:\n",
    "        print(\"No misclassifications found!\")\n",
    "        return\n",
    "    \n",
    "    n = len(misclassified)\n",
    "    cols = 4\n",
    "    rows = (n + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(3*cols, 3*rows))\n",
    "    axes = axes.flatten() if n > 1 else [axes]\n",
    "    \n",
    "    # denormalisation \n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    # plot misclassified images\n",
    "    for i, (img, true_label, pred_label) in enumerate(misclassified):\n",
    "        img = (img * std + mean).permute(1, 2, 0).clamp(0, 1)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis(\"off\")\n",
    "        axes[i].set_title(f\"T: {class_names[true_label]}\\nP: {class_names[pred_label]}\", \n",
    "                         fontsize=10)\n",
    "    \n",
    "    for i in range(n, len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adc0973",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_misclassified(model_resnet18, test_loader, device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc486540",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_misclassified(model_eff, test_loader, device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_correct = (y_pred_eff == y_true) & (y_pred_res == y_true)\n",
    "eff_only     = (y_pred_eff == y_true) & (y_pred_res != y_true)\n",
    "res_only     = (y_pred_eff != y_true) & (y_pred_res == y_true)\n",
    "both_wrong   = (y_pred_eff != y_true) & (y_pred_res != y_true)\n",
    "\n",
    "print(f\"Samples both correct:    {both_correct.sum()}\")\n",
    "print(f\"EfficientNet only right: {eff_only.sum()}\")\n",
    "print(f\"ResNet18 only right:     {res_only.sum()}\")\n",
    "print(f\"Both wrong:              {both_wrong.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79dd4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_latency(model, dataloader, n_batches=10):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    times = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, _) in enumerate(dataloader):\n",
    "            if i >= n_batches:\n",
    "                break\n",
    "            \n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Single timing measurement\n",
    "            start = time.perf_counter()\n",
    "            _ = model(images)\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "            end = time.perf_counter()\n",
    "            \n",
    "            times.append((end - start) / images.size(0))\n",
    "    \n",
    "    return torch.tensor(times).mean(), torch.tensor(times).std()\n",
    "\n",
    "# effnet and resnet\n",
    "mean_eff, std_eff = measure_latency(model, test_loader)\n",
    "mean_res, std_res = measure_latency(model_resnet18, test_loader)\n",
    "\n",
    "print(f\"EfficientNet: {mean_eff*1000:.2f} ± {std_eff*1000:.2f} ms / image\")\n",
    "print(f\"ResNet18:     {mean_res*1000:.2f} ± {std_res*1000:.2f} ms / image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff7c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latency values (in ms)\n",
    "models = [\"EfficientNet\", \"ResNet18\"]\n",
    "means = [mean_eff*1000, mean_res*1000]\n",
    "stds = [std_eff*1000, std_res*1000]\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(models, means, yerr=stds, capsize=8, color='#5F98E2')\n",
    "plt.ylabel(\"Latency (ms per image)\")\n",
    "plt.title(\"Model Inference Latency Comparison\")\n",
    "plt.grid(axis='y', alpha=0.4)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
