{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5129e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ResNet18 Model\n",
    "from torchvision import models\n",
    "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb30f1",
   "metadata": {},
   "source": [
    "We have loaded a ResNet-18 model that has already been trained on the ImageNet dataset. ImageNet has 1.2 million labelled images across 1000 categories. Because of this huge training, Resnet-18 has already learned general features such as edges, textures and simple shapes ect..\n",
    "\n",
    "ref = \"https://docs.pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html\"\n",
    "\n",
    "The following cells uses code adapted from the Transfer Learning section of: \"https://learnopencv.com/image-classification-using-transfer-learning-in-pytorch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d09d3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m     param.requires_grad = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#replace final layer for 43 traffic sign classes \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model.fc = \u001b[43mtorch\u001b[49m.nn.Linear(model.fc.in_features, \u001b[32m43\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#Freeze all backbone layers \n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#replace final layer for 43 traffic sign classes \n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab42247",
   "metadata": {},
   "source": [
    "ref for torch.nn.Linear = \"https://docs.pytorch.org/vision/stable/_modules/torchvision/models/resnet.html#ResNet18_Weights \"\n",
    "\n",
    "We freeze the backbone layers because ResNet 18 already knows how to see edges, colours, textures from being trained on ImageNet. We don't need to retrain all of that, it would take hours.\n",
    "\n",
    "Then, we replace the final layer. The original ResNet 18 can classify 1000 ImageNet classes, but our dataset has 43 traffic sign classes. So we simply swap the final layer for a new one that outputs 43 categories instead of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "#loss function (CrossEntropy = Softmax + NLL combined)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimiser (only train final layer)\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1bdf8a",
   "metadata": {},
   "source": [
    "loss_func = \"https://docs.pytorch.org/docs/stable/nn.html#loss-functions\"\n",
    "\n",
    "CrossEntropyLoss is the standard loss for multi-class classification, GTSRB has 43 classes, so this is the appropiate choice. Adam updates only the new classifier layer so ResNets learned ImageNet features stay frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f206fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resnet-18 Training Loop \n",
    "import torch \n",
    "from torch.autograd import Variable\n",
    "\n",
    "epochs = 10  \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "\n",
    "        #move to CPU (my mac has no GPU)\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        #Zero the gradients of the final layer \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        #Loss\n",
    "        loss = loss_func(outputs, labels )\n",
    "\n",
    "        #Backprop (only final layer updates)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Track Statistics \n",
    "        # accumulate loss and correct predictions\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    # compute full-dataset train metrics\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_acc = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "    # VALIDATION \n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            val_running_corrects += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    val_acc = val_running_corrects / len(val_loader.dataset)\n",
    "\n",
    "    # print 4 values\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"Train Loss {train_loss:.4f} | Acc {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss {val_loss:.4f} | Acc {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbab70a",
   "metadata": {},
   "source": [
    "The training and validation accuraxy remain close throughout, showing that the model is learning generalisable features rather than memorising the training set. After around Epoch 6-7, improvements slow down, suggesting the model is approaching its performance plateau.\n",
    "\n",
    "ref : training section = \"https://learnopencv.com/image-classification-using-transfer-learning-in-pytorch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4850cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a file to store learned weights - inform leo of the new name \n",
    "\n",
    "torch.save(model.state_dict(), \"resnet18_stage1_reduced.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1580c34b",
   "metadata": {},
   "source": [
    "After running the baseline model, we are now going to fine tune. We start by unfreezing the last ResNet 18 Block (layer 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f15437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the last ResNet block for fine-tuning\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layer4\" in name:     # last residual block\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aedc91a",
   "metadata": {},
   "source": [
    "Next we set up two different learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f98442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two learning-rate optimizer \n",
    "\n",
    "classifier_params = list(model.fc.parameters())\n",
    "\n",
    "layer4_params = [\n",
    "    p for name, p in model.named_parameters()\n",
    "    if name.startswith('layer4')\n",
    "]\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": model.fc.parameters(), \"lr\": 1e-3},      # classifier head\n",
    "    {\"params\": model.layer4.parameters(), \"lr\": 1e-4}   # fine-tuned block\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d0318",
   "metadata": {},
   "source": [
    "Next we create learning rate scheduler to automatically reduce the learning rate when the model stops improving. And we set up early- stopping variables that will stop the training early when the validation loss gets for for serveral epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0247e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the learning rate scheduler \n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb9123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping variables\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = 5\n",
    "wait = 0\n",
    "best_model_state = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f68d345",
   "metadata": {},
   "source": [
    "Now we will run the fine tuning loop again but with the fine tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2390af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tuning applied onto resnet loop \n",
    "\n",
    "import copy\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_acc = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "    #  validation\n",
    "    model.eval()\n",
    "    val_running_loss = 0\n",
    "    val_running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            val_running_corrects += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    val_acc = val_running_corrects / len(val_loader.dataset)\n",
    "\n",
    "    #scheduler step\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Train Loss {train_loss:.4f} | Acc {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss {val_loss:.4f} | Acc {val_acc:.4f}\")\n",
    "\n",
    "    # Early stopping \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_state, \"resnet18_best_finetuned.pth\")\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3269e1",
   "metadata": {},
   "source": [
    "As we can see, fine- tuning produces a very rapid improvement in performance, with the validation accuracy starting above 95% and reaching ~97.7%. both training and validation losses decrease smoothly (see plots), showing stable optimisation without signs of overfitting. Compared to our baseline model, this fine-tund stage achieves a large improvemnet, confirming that updating the backbone layers in crucial for extracting more detailed traffic-sign features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afaaf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually creating the history as I had issues with running it again\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": [0.3199, 0.1161, 0.0697, 0.0525, 0.0338],\n",
    "    \"train_acc\":  [0.8968, 0.9640, 0.9783, 0.9841, 0.9894],\n",
    "    \"val_loss\":   [0.1476, 0.1071, 0.0843, 0.0728, 0.0668],\n",
    "    \"val_acc\":    [0.9513, 0.9671, 0.9725, 0.9753, 0.9768]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fcd833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising Training Curves for ResNet18\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_range = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# ---- Loss Curve ----\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(epochs_range, history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"ResNet18 Training vs Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# ---- Accuracy Curve ----\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, history[\"train_acc\"], label=\"Train Accuracy\")\n",
    "plt.plot(epochs_range, history[\"val_acc\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"ResNet18 Training vs Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42850a7a",
   "metadata": {},
   "source": [
    "Training vs Validation Loss Comments:\n",
    "\n",
    "- Both the training loss and validation loss deacrease steadily across epochs, whcih indicates that the model is learning effectively.\n",
    "- The validation loss decreases smoothly, suggesting the fine-tuned ResNet 18 generalises well to unseen images.\n",
    "\n",
    "Training vs Validation Accuracy Comments:\n",
    "\n",
    "- Both training and validation accuracy increase consistently over the 5 epochs.\n",
    "- By the fifth epoch, validation accuracy tsabilises at ~0.977, indicating excellent generalisation without signs of overfitting.-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# Recreate architecture\n",
    "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "# Freeze backbone \n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Replace classifier head\n",
    "model.fc = nn.Linear(model.fc.in_features, 43)\n",
    "\n",
    "# Load saved fine-tuned weights\n",
    "model.load_state_dict(torch.load(\"resnet18_best_finetuned.pth\"))\n",
    "model.eval()\n",
    "\n",
    "print(\"Restored model ready for evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d4e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification and confusion matrix \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load best model state (ensures evaluation uses best checkpoint)\n",
    "model.load_state_dict(torch.load(\"resnet18_best_finetuned.pth\"))\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, zero_division=0))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=False, cmap=\"Blues\")\n",
    "plt.title(\"ResNet18 â€“ Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54685d48",
   "metadata": {},
   "source": [
    "This confusion matric is strongly diagonal, indicating that for almost all classes, the predicted label matches the true labels. This shows a very strong classificiation performance across the 43 traffic sign classes in the GTSRB dataset.\n",
    "\n",
    "The overall accuracy of 0.98 from the classification report show that performance is strong even for minority classes, suggesting the downsampled training strategy and fine-tuning approach were effective.\n",
    "\n",
    "Next we do few shot learning.\n",
    "\n",
    "To prepare we first create a function sample_few_shot that allows us to subsample the training dataset so that each class contains only k examples.\n",
    "\n",
    "We then make a training functions train_classifier only that freezes entire ResNet18 backbones and trains only the final classifier layer. The function will return validation accuracy for each few-shot scenario, allowing us to quantify how performance changes as the number of examples per class decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1162692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_few_shot(df, k):\n",
    "    \"\"\"\n",
    "    Return a dataframe where each class has exactly k samples.\n",
    "    \"\"\"\n",
    "    few_shot_df = df.groupby(\"ClassId\").apply(\n",
    "        lambda x: x.sample(k, replace=False)\n",
    "    ).reset_index(drop=True)\n",
    "    return few_shot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa66bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_only(model, train_loader, val_loader, epochs=3):\n",
    "    \"\"\"\n",
    "    Train only the final classifier layer for few-shot experiments.\n",
    "    \"\"\"\n",
    "\n",
    "    # Freeze backbone\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"fc\" not in name:   # only classifier head trains\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_corrects = 0\n",
    "        running_loss = 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # validation accuracy\n",
    "        model.eval()\n",
    "        val_corrects = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                outputs = model(imgs)\n",
    "                preds = outputs.argmax(1)\n",
    "                val_corrects += (preds == labels).sum().item()\n",
    "\n",
    "    val_acc = val_corrects / len(val_loader.dataset)\n",
    "    return val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f991cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_sizes = [1, 5, 10, 20, 40]\n",
    "results = {}\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "for k in shot_sizes:\n",
    "    print(f\"\\nRunning Few-Shot Learning with {k} samples per class...\")\n",
    "\n",
    "    # sample dataset\n",
    "    few_df = sample_few_shot(train_df, k)\n",
    "\n",
    "    # create dataset + loader\n",
    "    few_train_set = GTSRBDataset(few_df, root_dir=root, transform=train_transform)\n",
    "    few_train_loader = DataLoader(few_train_set, batch_size=32, shuffle=True)\n",
    "\n",
    "    #reuse full validation set\n",
    "    few_val_loader = val_loader\n",
    "\n",
    "    # reload a fresh model for each experiment\n",
    "    model_fs = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "    model_fs.fc = nn.Linear(model_fs.fc.in_features, 43)\n",
    "\n",
    "    # train classifier only\n",
    "    acc = train_classifier_only(model_fs, few_train_loader, few_val_loader)\n",
    "\n",
    "    results[k] = acc\n",
    "    print(f\"Validation Accuracy with {k} shots: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207752d2",
   "metadata": {},
   "source": [
    "There are a few quick observations from these results:\n",
    "\n",
    "- Accuracy increases as you add more examples per class.\n",
    "- Performance is extremely low with 1 or 5 shots, the model cannot generalised well when the classifier head is trained on such tiny data.\n",
    "- The growth is smooth, not flat (see curve below). This clarifies a key point that more data per class = better accuracy, thus confirms the value and necessity of finetuning with more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c512e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "shots = list(results.keys())\n",
    "accs = [results[k] for k in shots]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(shots, accs, marker='o')\n",
    "plt.title(\"Few-Shot Learning Curve (ResNet18 Classifier Only)\")\n",
    "plt.xlabel(\"Shots per Class\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
